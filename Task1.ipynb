{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 1. Install Dependencies\n",
        "# ----------------------------\n",
        "!pip install kagglehub pandas requests tqdm numpy\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Imports\n",
        "# ----------------------------\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# ----------------------------\n",
        "# 3. OpenRouter API Key\n",
        "# ----------------------------\n",
        "OPENROUTER_API_KEY = \"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\"\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Download Dataset\n",
        "# ----------------------------\n",
        "path = kagglehub.dataset_download(\"omkarsabnis/yelp-reviews-dataset\")\n",
        "print(\"Dataset path:\", path)\n",
        "\n",
        "print(\"\\nFiles in dataset directory:\")\n",
        "print(os.listdir(path))\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Load CSV Safely\n",
        "# ----------------------------\n",
        "csv_file = None\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith(\".csv\"):\n",
        "        csv_file = file\n",
        "        break\n",
        "\n",
        "if csv_file is None:\n",
        "    raise FileNotFoundError(\"No CSV file found in dataset directory.\")\n",
        "\n",
        "print(\"\\nUsing CSV file:\", csv_file)\n",
        "\n",
        "df = pd.read_csv(os.path.join(path, csv_file))\n",
        "print(\"\\nOriginal columns:\", df.columns.tolist())\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Normalize Column Names\n",
        "# ----------------------------\n",
        "# Common variations handled safely\n",
        "column_map = {\n",
        "    \"review_text\": \"review_text\",\n",
        "    \"text\": \"review_text\",\n",
        "    \"review\": \"review_text\",\n",
        "    \"stars\": \"stars\",\n",
        "    \"rating\": \"stars\"\n",
        "}\n",
        "\n",
        "df = df.rename(columns={c: column_map[c] for c in df.columns if c in column_map})\n",
        "\n",
        "if \"review_text\" not in df.columns or \"stars\" not in df.columns:\n",
        "    raise KeyError(\"Required columns not found. Expected review_text and stars.\")\n",
        "\n",
        "df = df[[\"review_text\", \"stars\"]].dropna()\n",
        "\n",
        "# Sample ~200 reviews\n",
        "df_sample = df.sample(200, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nSample size:\", len(df_sample))\n",
        "\n",
        "# ----------------------------\n",
        "# 7. OpenRouter API Call\n",
        "# ----------------------------\n",
        "def query_llm(prompt):\n",
        "    response = requests.post(\n",
        "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": \"openai/gpt-4o-mini\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "            \"temperature\": 0\n",
        "        },\n",
        "        timeout=30\n",
        "    )\n",
        "    return response.json()\n",
        "\n",
        "# ----------------------------\n",
        "# 8. Prompt Templates\n",
        "# ----------------------------\n",
        "PROMPT_1_ZERO_SHOT = \"\"\"\n",
        "You are an AI assistant.\n",
        "\n",
        "Given the following Yelp review, predict the star rating from 1 to 5.\n",
        "\n",
        "Review:\n",
        "\"{review_text}\"\n",
        "\n",
        "Return the result in valid JSON format:\n",
        "{{\n",
        "  \"predicted_stars\": integer,\n",
        "  \"explanation\": \"brief reason\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_2_SENTIMENT_ANCHORED = \"\"\"\n",
        "You are an expert sentiment analysis system trained on Yelp reviews.\n",
        "\n",
        "Classification rules:\n",
        "1 star = very negative experience\n",
        "2 stars = negative\n",
        "3 stars = neutral or mixed\n",
        "4 stars = positive\n",
        "5 stars = extremely positive\n",
        "\n",
        "Review:\n",
        "\"{review_text}\"\n",
        "\n",
        "Respond ONLY in valid JSON:\n",
        "{{\n",
        "  \"predicted_stars\": number,\n",
        "  \"explanation\": \"short justification\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_3_STRICT_JSON = \"\"\"\n",
        "You are a strict JSON-only API.\n",
        "\n",
        "Task:\n",
        "Predict Yelp review rating from 1 to 5 stars.\n",
        "\n",
        "Rules:\n",
        "- Output MUST be valid JSON\n",
        "- No extra text\n",
        "- Use integers only\n",
        "- Double-check sentiment before responding\n",
        "\n",
        "Review:\n",
        "\"{review_text}\"\n",
        "\n",
        "Output format:\n",
        "{{\n",
        "  \"predicted_stars\": 1-5,\n",
        "  \"explanation\": \"one sentence\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "PROMPTS = {\n",
        "    \"Zero-Shot\": PROMPT_1_ZERO_SHOT,\n",
        "    \"Sentiment-Anchored\": PROMPT_2_SENTIMENT_ANCHORED,\n",
        "    \"Strict-JSON\": PROMPT_3_STRICT_JSON\n",
        "}\n",
        "\n",
        "# ----------------------------\n",
        "# 9. Evaluation Function\n",
        "# ----------------------------\n",
        "def evaluate_prompt(prompt_template, runs=2):\n",
        "    all_predictions = []\n",
        "    valid_json_count = 0\n",
        "\n",
        "    for run in range(runs):\n",
        "        predictions = []\n",
        "\n",
        "        for _, row in tqdm(df_sample.iterrows(), total=len(df_sample)):\n",
        "            prompt = prompt_template.format(review_text=row[\"review_text\"])\n",
        "            response = query_llm(prompt)\n",
        "\n",
        "            try:\n",
        "                content = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "                parsed = json.loads(content)\n",
        "                pred = int(parsed[\"predicted_stars\"])\n",
        "\n",
        "                if 1 <= pred <= 5:\n",
        "                    predictions.append(pred)\n",
        "                    valid_json_count += 1\n",
        "                else:\n",
        "                    predictions.append(None)\n",
        "            except:\n",
        "                predictions.append(None)\n",
        "\n",
        "        all_predictions.append(predictions)\n",
        "\n",
        "    # Accuracy\n",
        "    correct, total = 0, 0\n",
        "    for pred, actual in zip(all_predictions[0], df_sample[\"stars\"]):\n",
        "        if pred is not None:\n",
        "            total += 1\n",
        "            if pred == actual:\n",
        "                correct += 1\n",
        "\n",
        "    accuracy = correct / total if total else 0\n",
        "\n",
        "    # Consistency (std deviation across runs)\n",
        "    consistency = 0.0\n",
        "    if runs > 1:\n",
        "        arr = np.array(all_predictions, dtype=float)\n",
        "        consistency = np.nanmean(np.nanstd(arr, axis=0))\n",
        "\n",
        "    json_validity = valid_json_count / (len(df_sample) * runs)\n",
        "\n",
        "    return accuracy, json_validity, consistency\n",
        "\n",
        "# ----------------------------\n",
        "# 10. Run Experiments\n",
        "# ----------------------------\n",
        "results = []\n",
        "\n",
        "for name, prompt in PROMPTS.items():\n",
        "    print(f\"\\nEvaluating Prompt Strategy: {name}\")\n",
        "    acc, json_rate, consistency = evaluate_prompt(prompt, runs=2)\n",
        "\n",
        "    results.append({\n",
        "        \"Prompt Strategy\": name,\n",
        "        \"Accuracy\": round(acc, 3),\n",
        "        \"JSON Validity Rate\": round(json_rate, 3),\n",
        "        \"Consistency (↓ better)\": round(consistency, 3)\n",
        "    })\n",
        "\n",
        "# ----------------------------\n",
        "# 11. Results Table\n",
        "# ----------------------------\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"\\n================ FINAL COMPARISON TABLE ================\\n\")\n",
        "print(results_df)\n",
        "\n",
        "# ----------------------------\n",
        "# 12. Save Results\n",
        "# ----------------------------\n",
        "results_df.to_csv(\"yelp_prompting_results.csv\", index=False)\n",
        "print(\"\\nResults saved as yelp_prompting_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYAI6bLmqWmU",
        "outputId": "8fa03441-b407-4f5f-d1f4-9169609b4a33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/omkarsabnis/yelp-reviews-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.49M/3.49M [00:00<00:00, 59.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset path: /root/.cache/kagglehub/datasets/omkarsabnis/yelp-reviews-dataset/versions/1\n",
            "\n",
            "Files in dataset directory:\n",
            "['yelp.csv']\n",
            "\n",
            "Using CSV file: yelp.csv\n",
            "\n",
            "Original columns: ['business_id', 'date', 'review_id', 'stars', 'text', 'type', 'user_id', 'cool', 'useful', 'funny']\n",
            "\n",
            "Sample size: 200\n",
            "\n",
            "Evaluating Prompt Strategy: Zero-Shot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [05:06<00:00,  1.53s/it]\n",
            "100%|██████████| 200/200 [04:52<00:00,  1.46s/it]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Prompt Strategy: Sentiment-Anchored\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [04:31<00:00,  1.36s/it]\n",
            "100%|██████████| 200/200 [05:20<00:00,  1.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Prompt Strategy: Strict-JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [05:02<00:00,  1.51s/it]\n",
            "100%|██████████| 200/200 [04:17<00:00,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ FINAL COMPARISON TABLE ================\n",
            "\n",
            "      Prompt Strategy  Accuracy  JSON Validity Rate  Consistency (↓ better)\n",
            "0           Zero-Shot     0.684                0.89                   0.000\n",
            "1  Sentiment-Anchored     0.680                1.00                   0.005\n",
            "2         Strict-JSON     0.630                1.00                   0.005\n",
            "\n",
            "Results saved as yelp_prompting_results.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kajrMD0Eygbp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}